Sahil Kumar 2022CS11100
Rajarshee Das 2022CS11124
In this assignment we were supposed to implement a game playing agent for Havannah specifically for board sizes of 4 and 6. Following were the strategies used for different board sizes and different time formats.
Board size 4:
For playing against random agent and the TA agent we implemented the simple MCTS with optimization because the search space after 2-3 moves becomes small enough that MCTS itself finds the optimal moves given sufficient time so we focused primarily on improving the efficiency of code so that it could run more iterations in the same amount of time to find the optimal moves. For making the code run fast, during rollout we did not created a node for every state rather kept modifying the same state for a rollout saving time of copying the states similarly we did not calculated the valid actions at each of the node rather just removed the action used to make the current node from the list of valid actions from parents. Also we did not created a copy of the objects wherever possible to save time. These simple optimizations with some other made our MCTS run a good amount of iterations and eventually find the best move in this small state space.

Board Size 6:
The main issue difference between the board size 6 and board size 4 was the state space which exploded in the case of 6, even with the above mentioned optimizations it was not able to run sufficient number of iterations to make reasonable moves so we decided to cut upon the search space so as to enable it to make the best move in that relatively small search space. The approach used to cut down the search space without much affecting the selection of global optimum moves was that whenever we expanded the nodes in MCTS we only created the children which either are direct neighbor of already occupied state of parent node or has a virtual connection with any of the node already occupied in the parent node. In this way we were not loosing on the important moves and also reduced the search space. This was working pretty well because most of the optimal moves are either direct neighbors or form virtual connections with already existing states. We did this strategy till the total moves played by both players are less than 50 after we applied MCTS as the size of state space becomes comparable to the state space of dimension 4. We also did a time distribution with initial 5 moves being relatively fast and then spending a lot of time in middle game to establish dominance, also in the end game the state space becomes small so MCTS can find optimal moves in relatively less time than the middle game. 

In both the games we implemented the feature that if we can win the game in one move just play that move and if we cannot win in the next move but opponent can win just block that move so even if MCTS missed it due to high state space we donot do any straightforward blunder.
We also tried with RAVE but aforementioned strategies were able to beat RAVE so we decided to stick with them. We also tried heuristics but in first case they made our program a bit slow,reducing iterations and making the performance go down which did not help and in the second case they were not performing very well because the MCTS due to time constraints was not able to build a good game from heuristics as it could not search very high depth due to less time per move available in board of dimension 6.
